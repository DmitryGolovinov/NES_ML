{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHgmxWG_7lnE"
      },
      "source": [
        "# Домашняя работа 6. Бустинг\n",
        "\n",
        " **Выполнил Дмитрий Головинов**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HneEm-I-7Zlz"
      },
      "source": [
        "Максимальная оценка 10 баллов\n",
        "\n",
        "Ответы на вопросы пишите в комментариях или в markdown ячейках. Таким же образом обозначайте блоки кода для лучшей читаемости (например, \"Обучим бэггинг на логистических регрессиях : ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\").\n",
        "\n",
        "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
        "\n",
        "**Оценка: 10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOqjUI6igeLc"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.optimize import minimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tKaz0okgeLh"
      },
      "source": [
        "### Задание 1. Градиентный бустинг своими руками  (4 балла)\n",
        "\n",
        "Вам нужно реализовать упрощенный вариант градиентного бутсинга для задачи регресси.\n",
        "\n",
        "\n",
        "**Напоминание, как это работает:**\n",
        "\n",
        "Обозначим текущую композицию на $N-1$ шаге за $a_{N - 1}(x_i)$. Базовый алгоритм $b_N(x_i)$ обучается на ответах $-\\frac{\\partial L(y_i, z)}{\\partial z}\\Bigl|_{z = a_{N - 1}(x_i)}$, где $L(y_i, z)$ — значение функции потерь на объекте при правильном ответе $y_i$ и предсказании $z$. Композиция на следующем шаге получается так:\n",
        "\n",
        "$$\n",
        "a_N(x_i) = a_{N-1}(x_i) + \\nu\\gamma_Nb_N(x_i)\n",
        "$$\n",
        "\n",
        "Здесь $\\nu \\in [0, 1]$ — темп обучения (гиперпараметр), $\\gamma_N$ — оптимальный вес, настраиваемый на каждом шаге алгоритма в ходе решения оптимизационной задачи:\n",
        "\n",
        "$$\n",
        "\\gamma_N = \\mathrm{arg}\\min_\\gamma \\frac{1}{\\ell}\\sum\\limits_{i=1}^{\\ell}L\\left(y_i, a_{N - 1}(x_i) + \\gamma b_N(x_i)\\right)\n",
        "$$\n",
        "\n",
        "\n",
        "Заметьте, что в формуле выше нет $\\nu$. Этот гиперпараметр используется для сокращения длины шага, оптимального при составлении композиции $a_N$. Идея отклонения от оптимума должна быть вам уже знакома как способ борьбы с переобучением, когда мы специально форсим модель работать чуть хуже, чем могла бы, на текущем шаге, чтобы сохранить обобщающую способность и не подогнаться под тренировочную выборку (или под шум).\n",
        "\n",
        "С потерей в 0.5 балла можете принять $\\gamma_N = 1$ для каждого $N$. На полный балл необходимо реализовать нахождение оптимального $\\gamma_N$ на каждом шаге.\n",
        "\n",
        "В качестве функции потерь $L$ возьмите MSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8UN4Qbr7Zl1"
      },
      "source": [
        "В качестве базовой модели можете использовать `DecisionTreeRegressor` из `sklearn`.\n",
        "Для решения оптимизационной задачки можно воспользоваться алгоритмами из любых библиотек, например, `scipy.optimize`, или найти оптимум перебором по сетке из некоторого разумного диапазона.\n",
        "\n",
        "Можно дописывать свои функции, если необходимо."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB5Yt-LKgeLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935915f8-5c02-43ed-b55b-e783660b726b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат: 0.3655720274211312\n",
            "Выдает ±0.165, что меньше чем Random Forest (0.167) - это хорошо\n"
          ]
        }
      ],
      "source": [
        "class GradientBoosting:\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_model_class: object = DecisionTreeRegressor,\n",
        "        base_model_params: dict = {'max_depth': 8},\n",
        "        n_estimators: int = 500,\n",
        "        learning_rate: float = 0.025\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          base_model_class: Class of the base learner.\n",
        "\n",
        "          base_model_params: Hyperparameters of the base learner.\n",
        "\n",
        "          n_estimators: Number of boosting stages.\n",
        "\n",
        "          learning_rate: Value used to shrink contribution of each base learner to the model.\n",
        "        \"\"\"\n",
        "        # Инициализация основных параметров модели\n",
        "        self.base_model_class = base_model_class\n",
        "        self.base_model_params = base_model_params\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Инициализация массивов для хранения значений гамма и базовых моделей\n",
        "        self.gamma_values = []\n",
        "        self.base_models = []\n",
        "\n",
        "    def find_optimal_gamma(self,\n",
        "                           y: np.array,\n",
        "                           old_predictions: np.array,\n",
        "                           new_predictions: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          y: Target variable.\n",
        "\n",
        "          old_predictions: Prediction of the additive model at the previous stage.\n",
        "\n",
        "          new_predictions: Prediction of the base learner at the current stage.\n",
        "\n",
        "        Returns:\n",
        "          Optimal value for gamma.\n",
        "        \"\"\"\n",
        "        # Функция потерь для оптимизации гамма\n",
        "        def loss_function(gamma):\n",
        "            return mean_squared_error(y, old_predictions + gamma * new_predictions)\n",
        "\n",
        "        initial_guess = 1.0\n",
        "        result = minimize(loss_function, initial_guess, method='Nelder-Mead')\n",
        "        optimal_gamma = result.x[0]\n",
        "\n",
        "        return optimal_gamma\n",
        "\n",
        "    def _fit_base_model(self, X: np.ndarray, y: np.array):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          X: Feature matrix\n",
        "\n",
        "          y: Target variable.\n",
        "\n",
        "        Returns:\n",
        "          Fitted base learner.\n",
        "        \"\"\"\n",
        "        # Обучение базовой модели\n",
        "        model = self.base_model_class(**self.base_model_params)\n",
        "        model.fit(X, y)\n",
        "        return model\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.array):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          X: Feature matrix\n",
        "\n",
        "          y: Target variable.\n",
        "\n",
        "        Returns:\n",
        "          Fitted boosting.\n",
        "        \"\"\"\n",
        "        # Процесс обучения ансамбля моделей\n",
        "        predictions = np.zeros(len(y))\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            # Вычисление остатков\n",
        "            residuals = y - predictions\n",
        "            # Обучение дополнительной модели\n",
        "            model = self._fit_base_model(X, residuals)\n",
        "            # Получение предсказаний от модели\n",
        "            new_predictions = model.predict(X)\n",
        "            # Добавление модели в список\n",
        "            self.base_models.append(model)\n",
        "            # Оптимизация гаммы\n",
        "            gamma_opt = self.find_optimal_gamma(y, predictions, new_predictions)\n",
        "            self.gamma_values.append(gamma_opt)\n",
        "            # Обновление общих предсказаний\n",
        "            predictions += self.learning_rate * gamma_opt * new_predictions\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: np.ndarray):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          X: Feature matrix\n",
        "\n",
        "        Returns:\n",
        "          Prediction of fitted boosting.\n",
        "        \"\"\"\n",
        "        # Получение предсказаний от ансамбля\n",
        "        predictions = np.zeros(X.shape[0])\n",
        "\n",
        "        for gamma, model in zip(self.gamma_values, self.base_models):\n",
        "            predictions += self.learning_rate * gamma * model.predict(X)\n",
        "        return predictions\n",
        "\n",
        "\n",
        "gb = GradientBoosting(base_model_class=DecisionTreeRegressor,\n",
        "                      base_model_params={'max_depth': 8},\n",
        "                      n_estimators=500,\n",
        "                      learning_rate=0.025) # Ручками подобрал параметры\n",
        "gb.fit(X_train, y_train)\n",
        "gb_mse = mean_squared_error(y_test, gb.predict(X_test))\n",
        "print(f\"Результат: {gb_mse}\")\n",
        "print(f\"Выдает ±0.165, что меньше чем Random Forest (0.167) - это хорошо\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqE0xVGg7Zl1"
      },
      "source": [
        "Проверьте вашу реализацию на бостонском датасете. Подберите оптимальные гиперпараметры, чтобы победить RandomForestRegressor (не меняйте параметры сида)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU7zdVJZ7Zl1"
      },
      "outputs": [],
      "source": [
        "housing = fetch_california_housing()\n",
        "X = housing.data[:5000]\n",
        "y = housing.target[:5000]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udNXLNm_7Zl2",
        "outputId": "e67170bc-0085-4a48-9783-d9846d7705b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1673784076585523"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(max_features=4, n_estimators=640, random_state=19052019)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "mean_squared_error(y_test, rf.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paNk4O_O7Zl2"
      },
      "source": [
        "### Задание 2. Сравнение подходов (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnTB5ptx7Zl2"
      },
      "source": [
        "Скачайте данные о выдаче кредитов. Это данные с kaggle, целевая переменная `y` показывает, вернуло ли кредит физическое лицо."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGa3fHmk7Zl2"
      },
      "outputs": [],
      "source": [
        "!wget  -O 'bank_data.csv' -q 'https://www.dropbox.com/s/uy27mctxo0gbuof/bank_data.csv?dl=0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "v054AH737Zl2",
        "outputId": "250c156a-ed37-4c25-8577-d977b06400d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age            job  marital            education default housing loan  \\\n",
              "490    32   entrepreneur   single  professional.course      no     yes   no   \n",
              "227    31       services   single             basic.6y      no      no   no   \n",
              "3567   43    blue-collar  married             basic.6y      no     yes   no   \n",
              "6249   26  self-employed  married    university.degree      no     yes   no   \n",
              "951    39         admin.  married    university.degree      no      no   no   \n",
              "\n",
              "        contact month day_of_week  ...  campaign  pdays  previous  \\\n",
              "490   telephone   aug         fri  ...         1    999         0   \n",
              "227   telephone   jun         wed  ...         3    999         0   \n",
              "3567   cellular   apr         fri  ...         1    999         1   \n",
              "6249  telephone   jun         wed  ...         1    999         0   \n",
              "951    cellular   jul         mon  ...         3    999         0   \n",
              "\n",
              "         poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
              "490   nonexistent         -1.7          94.027          -38.3      0.905   \n",
              "227   nonexistent          1.4          94.465          -41.8      4.962   \n",
              "3567      failure         -1.8          93.075          -47.1      1.405   \n",
              "6249  nonexistent          1.4          94.465          -41.8      4.864   \n",
              "951   nonexistent          1.4          93.918          -42.7      4.962   \n",
              "\n",
              "      nr.employed  y  \n",
              "490        4991.6 -1  \n",
              "227        5228.1 -1  \n",
              "3567       5099.1 -1  \n",
              "6249       5228.1 -1  \n",
              "951        5228.1 -1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-158107fa-39d5-461b-b1f3-05217d596c53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>...</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>32</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>single</td>\n",
              "      <td>professional.course</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>aug</td>\n",
              "      <td>fri</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>94.027</td>\n",
              "      <td>-38.3</td>\n",
              "      <td>0.905</td>\n",
              "      <td>4991.6</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>31</td>\n",
              "      <td>services</td>\n",
              "      <td>single</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>jun</td>\n",
              "      <td>wed</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.4</td>\n",
              "      <td>94.465</td>\n",
              "      <td>-41.8</td>\n",
              "      <td>4.962</td>\n",
              "      <td>5228.1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3567</th>\n",
              "      <td>43</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>apr</td>\n",
              "      <td>fri</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>1</td>\n",
              "      <td>failure</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>93.075</td>\n",
              "      <td>-47.1</td>\n",
              "      <td>1.405</td>\n",
              "      <td>5099.1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6249</th>\n",
              "      <td>26</td>\n",
              "      <td>self-employed</td>\n",
              "      <td>married</td>\n",
              "      <td>university.degree</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>jun</td>\n",
              "      <td>wed</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.4</td>\n",
              "      <td>94.465</td>\n",
              "      <td>-41.8</td>\n",
              "      <td>4.864</td>\n",
              "      <td>5228.1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>39</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>university.degree</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>jul</td>\n",
              "      <td>mon</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.4</td>\n",
              "      <td>93.918</td>\n",
              "      <td>-42.7</td>\n",
              "      <td>4.962</td>\n",
              "      <td>5228.1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-158107fa-39d5-461b-b1f3-05217d596c53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-158107fa-39d5-461b-b1f3-05217d596c53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-158107fa-39d5-461b-b1f3-05217d596c53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-786786e0-2191-4597-9693-4fceee1383e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-786786e0-2191-4597-9693-4fceee1383e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-786786e0-2191-4597-9693-4fceee1383e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "df = pd.read_csv('bank_data.csv')\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xna-FIQ7Zl2"
      },
      "source": [
        "Решите задачу предсказания возвращения кредита методами, перечисленными ниже:\n",
        "\n",
        "- Случайный лес\n",
        "- Бэггинг на деревьях (поставьте для базовых деревьев min_samples_leaf=1)\n",
        "- Бэггинг, у которого базовой моделью является бустинг с большим числом деревьев (> 100)\n",
        "- Бэггинг на логистических регрессиях\n",
        "\n",
        "Используйте логистическую регрессию, случайный лес, `GradientBoostingClassifier` и `BaggingClassifier` из `sklearn`.\n",
        "\n",
        "1) Какая из моделей имеет лучшее качество? С чем это связано?\n",
        "\n",
        "2) Какая из моделей сильнее всего переобучается?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw7ZFv7P7Zl2",
        "outputId": "311799cd-1ccd-441d-9073-064defa8afdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest: Точность: 0.8887005388760587 (+/- 0.007207176933175411)\n",
            "Bagging on Trees: Точность: 0.8763845561674662 (+/- 0.009415787544622802)\n",
            "Bagging with Boosting: Точность: 0.8891613667318055 (+/- 0.011061260887802703)\n",
            "Bagging on Logistic Regression: Точность: 0.8759232545745247 (+/- 0.015695172520400473)\n",
            "Random Forest: На обучающей выборке: 1.0, На тестовой выборке: 0.8811063218390804\n",
            "Bagging on Trees: На обучающей выборке: 0.9921490147783252, На тестовой выборке: 0.8742816091954023\n",
            "Bagging with Boosting: На обучающей выборке: 0.9005541871921182, На тестовой выборке: 0.884698275862069\n",
            "Bagging on Logistic Regression: На обучающей выборке: 0.8802339901477833, На тестовой выборке: 0.8674568965517241\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Преобразование категориальных признаков\n",
        "df_dummies = pd.get_dummies(df)\n",
        "\n",
        "# Подготовка данных\n",
        "X = df_dummies.drop('y', axis=1)\n",
        "y = df_dummies['y']\n",
        "\n",
        "#Отнормируем данные\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Обучение моделей и оценка их качества\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Bagging on Trees\": BaggingClassifier(estimator=DecisionTreeClassifier(min_samples_leaf=1), random_state=42),\n",
        "    \"Bagging with Boosting\": BaggingClassifier(estimator=GradientBoostingClassifier(n_estimators=100), random_state=42),\n",
        "    \"Bagging on Logistic Regression\": BaggingClassifier(estimator=LogisticRegression(), random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    print(f\"{name}: Точность: {scores.mean()} (+/- {scores.std() * 2})\")\n",
        "\n",
        "# Качество на обучающей и тестовой выборке\n",
        "for name, model in models.items():\n",
        "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(f\"{name}: На обучающей выборке: {train_accuracy}, На тестовой выборке: {test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ОТВЕТЫ НА ВОПРОСЫ** 1) Лучшие модели это Random forest и Bagging with Boosting. Хотя разница между результатами моделей на тестовых выборках мала <0.01, если предположить что это значимо, возможно это связано с меньшим подверженностям выбросам.\n",
        "\n",
        "2) Я бы не сказал, что кто-то особенно переучился, ведь по определению, переобучение это хорошая работа на обучающей выборке и плохая работа на тестовой. В данном случае, все модели показали хорошую работу на тестовой выборке. Сильнее всего \"переобучился\" на обучающей выборке Random Forest (100%)."
      ],
      "metadata": {
        "id": "fI42e5VohvZL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrLogXTU7Zl2"
      },
      "source": [
        "### Задание 3. Современные бустинги (3 балла)\n",
        "\n",
        "Сравните на этих данных любую из трёх популярных имплементаций градиентного бустинга (xgboost, lightgbm, catboost). Подберите основные гиперпараметры (число деревьев, длина шага, глубина дерева/число листьев). Получилось ли круче, чем с моделями выше?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zp5Mjr77Zl2",
        "outputId": "a8655b50-ce60-4679-d4a1-08dd10a3fc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3269, number of negative: 3227\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003723 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 777\n",
            "[LightGBM] [Info] Number of data points in the train set: 6496, number of used features: 60\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503233 -> initscore=0.012931\n",
            "[LightGBM] [Info] Start training from score 0.012931\n",
            "[LightGBM] [Info] Number of positive: 2615, number of negative: 2581\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 769\n",
            "[LightGBM] [Info] Number of data points in the train set: 5196, number of used features: 60\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503272 -> initscore=0.013087\n",
            "[LightGBM] [Info] Start training from score 0.013087\n",
            "[LightGBM] [Info] Number of positive: 2615, number of negative: 2582\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002837 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 764\n",
            "[LightGBM] [Info] Number of data points in the train set: 5197, number of used features: 60\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503175 -> initscore=0.012700\n",
            "[LightGBM] [Info] Start training from score 0.012700\n",
            "[LightGBM] [Info] Number of positive: 2615, number of negative: 2582\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 771\n",
            "[LightGBM] [Info] Number of data points in the train set: 5197, number of used features: 60\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503175 -> initscore=0.012700\n",
            "[LightGBM] [Info] Start training from score 0.012700\n",
            "[LightGBM] [Info] Number of positive: 2615, number of negative: 2582\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002964 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 766\n",
            "[LightGBM] [Info] Number of data points in the train set: 5197, number of used features: 60\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503175 -> initscore=0.012700\n",
            "[LightGBM] [Info] Start training from score 0.012700\n",
            "[LightGBM] [Info] Number of positive: 2616, number of negative: 2581\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 770\n",
            "[LightGBM] [Info] Number of data points in the train set: 5197, number of used features: 60\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503367 -> initscore=0.013470\n",
            "[LightGBM] [Info] Start training from score 0.013470\n",
            "Optimized LightGBM Accuracy: 0.8937797122046545\n",
            "Выдает >0.89, что лучше, чем предыдущие результаты\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Преобразование категориальных переменных\n",
        "df_dummies = pd.get_dummies(df)\n",
        "X = df_dummies.drop('y', axis=1)\n",
        "y = df_dummies['y']\n",
        "\n",
        "# Масштабирование данных\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Создание и обучение модели LightGBM\n",
        "lgbm = LGBMClassifier(**params)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Оценка точности модели\n",
        "lgbm_accuracy = cross_val_score(lgbm, X_train, y_train, cv=5).mean()\n",
        "print(f\"Optimized LightGBM Accuracy: {lgbm_accuracy}\")\n",
        "print(\"Выдает >0.89, что лучше, чем предыдущие результаты\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "pyoadfe",
      "language": "python",
      "name": "pyoadfe"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}